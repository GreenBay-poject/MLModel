{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        image_name                                           tags\n",
      "0          train_0                                   haze primary\n",
      "1          train_1                agriculture clear primary water\n",
      "2          train_2                                  clear primary\n",
      "3          train_3                                  clear primary\n",
      "4          train_4      agriculture clear habitation primary road\n",
      "...            ...                                            ...\n",
      "40474  train_40474                                  clear primary\n",
      "40475  train_40475                                         cloudy\n",
      "40476  train_40476                      agriculture clear primary\n",
      "40477  train_40477                 agriculture clear primary road\n",
      "40478  train_40478  agriculture cultivation partly_cloudy primary\n",
      "\n",
      "[40479 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "df = pd.read_csv (r'train.csv')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdictionary={}\n",
    "columns=(df.tags.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventional_mine', 100), ('blow_down', 101), ('slash_burn', 209), ('blooming', 332), ('artisinal_mine', 339), ('selective_logging', 340), ('bare_ground', 862), ('cloudy', 2089), ('haze', 2697), ('habitation', 3660), ('cultivation', 4547), ('partly_cloudy', 7261), ('water', 7411), ('road', 8071), ('agriculture', 12315), ('clear', 28431), ('primary', 37513)]\n"
     ]
    }
   ],
   "source": [
    "for i in columns:\n",
    "    words=i.split()\n",
    "    for j in words:\n",
    "        if j in tagdictionary.keys():\n",
    "            tagdictionary[j]=tagdictionary[j]+1\n",
    "        else:\n",
    "            tagdictionary[j]=1\n",
    "dactictionarysorted=sorted(tagdictionary.items(),key=lambda x:x[1])\n",
    "print(dactictionarysorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n"
     ]
    }
   ],
   "source": [
    "taglist=list(tagdictionary.keys())\n",
    "print(taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def encodingbinaryArray(taglist,tags):\n",
    "    encoding=np.zeros(len(taglist),dtype='uint8')\n",
    "    #print(type(encoding))\n",
    "    for tag in tags:\n",
    "        index=taglist.index(tag)\n",
    "        encoding[index]=1\n",
    "    return encoding\n",
    "print(encodingbinaryArray(taglist,[\"clear\",\"cloudy\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_0', 'train_1', 'train_2', 'train_3', 'train_4', 'train_5', 'train_6', 'train_7', 'train_8', 'train_9', 'train_10', 'train_11', 'train_12', 'train_13', 'train_14', 'train_15', 'train_16', 'train_17', 'train_18', 'train_19']\n",
      "[['haze', 'primary'], ['agriculture', 'clear', 'primary', 'water'], ['clear', 'primary'], ['clear', 'primary'], ['agriculture', 'clear', 'habitation', 'primary', 'road'], ['haze', 'primary', 'water'], ['agriculture', 'clear', 'cultivation', 'primary', 'water'], ['haze', 'primary'], ['agriculture', 'clear', 'cultivation', 'primary'], ['agriculture', 'clear', 'cultivation', 'primary', 'road'], ['agriculture', 'clear', 'primary', 'slash_burn', 'water'], ['clear', 'primary', 'water'], ['cloudy'], ['clear', 'primary'], ['cloudy'], ['clear', 'primary'], ['clear', 'primary'], ['partly_cloudy', 'primary'], ['clear', 'primary'], ['agriculture', 'clear', 'primary', 'road']]\n"
     ]
    }
   ],
   "source": [
    "def filePrepare(df):\n",
    "    imgnames=df.image_name.tolist()\n",
    "    tags=[]\n",
    "    for s in df.tags.tolist():\n",
    "        tags.append(s.split(\" \"))\n",
    "    return [imgnames,tags]\n",
    "result=filePrepare(df)\n",
    "print(result[0][0:20])\n",
    "print(result[1][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodingBinaryPrepare(tags):\n",
    "    encodedlist=[]\n",
    "    for i in tags:\n",
    "        encodedlist.append(encodingbinaryArray(taglist,i))\n",
    "                        \n",
    "    return encodedlist\n",
    "\n",
    "\n",
    "file_names=result[0]\n",
    "file_tags=encodingBinaryPrepare(result[1]) \n",
    "#print(file_names)\n",
    "#print(file_tags)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128, 128, 3)\n",
      "(1000, 17)\n"
     ]
    }
   ],
   "source": [
    "def prepare_X_y(path,file_names,file_tags):\n",
    "    photos,codes=list(),list()\n",
    "    i=0\n",
    "    for file_name in file_names[0:1000]:\n",
    "        #dirname = os.path.dirname(__file__)\n",
    "        realfilename = 'train-jpg/'+file_name+'.jpg'\n",
    "        photo=load_img(realfilename,target_size=(128,128))\n",
    "        photo=img_to_array(photo,dtype=\"uint8\")\n",
    "        photos.append(photo)\n",
    "        codes.append(file_tags[i])\n",
    "        i=i+1\n",
    "    \n",
    "    X=np.asarray(photos,dtype='uint8')\n",
    "    y=np.asarray(codes,dtype='uint8')\n",
    "    return X,y\n",
    "X,y=prepare_X_y(\"path\",file_names,file_tags)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('Loaded_Images_Tags.npz',X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "\n",
    "def divide_train_test():\n",
    "    data=np.load('Loaded_Images_Tags.npz')\n",
    "    X,y=data['arr_0'],data['arr_1']\n",
    "    \n",
    "    trainX,testX,trainY,testY=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "    print(trainX.shape,testX.shape,trainY.shape,testY.shape)\n",
    "    return trainX,testX,trainY,testY\n",
    "\n",
    "#trainX,testX,trainY,testY=divide_train_test()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    r = tp / (tp + fn + backend.epsilon())\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(out_shape, activation='sigmoid'))\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ploting_graphs(history):\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Fbeta')\n",
    "    pyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "    pyplot.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 4,483,633\n",
      "Trainable params: 4,483,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=\"high_accuracy.hdf5\", \n",
    "                               monitor = 'val_accuracy',\n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 128, 128, 3) (300, 128, 128, 3) (700, 17) (300, 17)\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 91s 15s/step - loss: 0.6053 - fbeta: 0.4671 - val_loss: 0.3800 - val_fbeta: 0.4049\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 85s 14s/step - loss: 0.3291 - fbeta: 0.4815 - val_loss: 0.4069 - val_fbeta: 0.6499\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 87s 14s/step - loss: 0.2980 - fbeta: 0.6411 - val_loss: 0.3463 - val_fbeta: 0.6658\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 85s 14s/step - loss: 0.2730 - fbeta: 0.6346 - val_loss: 0.3224 - val_fbeta: 0.6550\n",
      "Epoch 5/5\n",
      "5/6 [========================>.....] - ETA: 11s - loss: 0.2605 - fbeta: 0.6418"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = divide_train_test()\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "\n",
    "# datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_it = train_datagen.flow(trainX, trainY, batch_size=128)\n",
    "test_it = test_datagen.flow(testX, testY, batch_size=128)\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "    validation_data=test_it, validation_steps=len(test_it), epochs=5, verbose=1) #epochs=50\n",
    "loss, fbeta = model.evaluate(test_it, steps=len(test_it), verbose=1)\n",
    "print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "ploting_graphs(history)\n",
    "model.save('Final_Model.h5')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
